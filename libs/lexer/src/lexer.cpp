#include "tachyon/lexer/lexer.h"

#include "tachyon/lexer/keyword_hash.h"

#include "fast_float/fast_float.h"

namespace tachyon::lexer {
// TODO: map here?
inline bool is_starting_number_char(const char *ch) {
    return (*ch >= '0' && *ch <= '9');
}

inline bool is_number_char(const char *ch) {
    return (*ch >= '0' && *ch <= '9') || *ch == '.';
}

inline bool is_starting_identifier_char(const char *ch) {
    return (*ch >= 'A' && *ch <= 'Z') || (*ch >= 'a' && *ch <= 'z') || *ch == '_' || *ch == '\'';
}

inline bool is_identifier_char(const char *ch) {
    return (*ch >= 'A' && *ch <= 'Z') || (*ch >= 'a' && *ch <= 'z') || (*ch >= '0' && *ch <= '9') ||
           *ch == '_' || *ch == '\'';
}

void Lexer::lex(const std::string &source_code) {
    current = &source_code[0];
    while (*current != '\0') {
        // consume comments
        if (*current == '/') {
            if (*(current + 1) == '/') {
                while (*current != '\n' && *current != '\0') {
                    ++current;
                }
                // consume newline
                if (*current == '\n') ++current;
                continue;
            } else if (*(current + 1) == '*') {
                ++current;
                while (!(*current == '/' && *(current - 1) == '*')) {
                    ++current;
                }
                ++current;
                continue;
            }
        }

        // fast path: hot single/double character tokens
        switch (*current) {
        case '\t':
        case ' ': ++current; continue;
        case '\n': consume_and_push(NLINE); continue;
        case '=':
            if (*(current + 1) == '=') consume_and_push(ECOMP, 2);
            else consume_and_push(EQ, 1);
            continue;
        case '!':
            if (*(current + 1) == '=') consume_and_push(NECOMP, 2);
            else consume_and_push(NOT);
            continue;
        case '+': consume_and_push(PLUS); continue;
        case '-':
            if (*(current + 1) == '>') consume_and_push(RARROW, 2);
            else consume_and_push(MINUS);
            continue;
        case '*': consume_and_push(STAR); continue;
        case '/': consume_and_push(FSLASH); continue;
        case '^': consume_and_push(CARET); continue;
        case '<':
            if (*(current + 1) == '=') consume_and_push(LECOMP, 2);
            else consume_and_push(LCOMP);
            continue;
        case '>':
            if (*(current + 1) == '=') consume_and_push(GECOMP, 2);
            else consume_and_push(GCOMP);
            continue;
        case '&':
            if (*(current + 1) == '&') {
                consume_and_push(BAND, 2);
                continue;
            }
        case '|':
            if (*(current + 1) == '|') {
                consume_and_push(BOR, 2);
                continue;
            }
        case '(':
            if (*(current + 1) == ')') consume_and_push(UNIT, 2);
            else consume_and_push(LPAREN);
            continue;
        case ')': consume_and_push(RPAREN); continue;
        case '{': consume_and_push(LBRACE); continue;
        case '}': consume_and_push(RBRACE); continue;
        case '[': consume_and_push(LBRACK); continue;
        case ']': consume_and_push(RBRACK); continue;
        case '.': consume_and_push(DOT); continue;
        case ':': consume_and_push(COLON); continue;
        case ';': consume_and_push(SEMIC); continue;
        case ',': consume_and_push(COMMA); continue;
        default:
        }

        // numbers, identifiers/keywords, and strings
        if (is_starting_number_char(current)) {
            const char *start = current;
            while (is_number_char(++current)) {
            }
            double value;
            auto answer = fast_float::from_chars(start, current, value);
            if (answer.ec != std::errc())
                errors.emplace_back(
                    Error::create(ErrorKind::LexError, SourceSpan(0, 0), "failed to read number"));
            constants.emplace_back(value);
            tokens.emplace_back(NUMBER, std::string_view(start, current), constants.size() - 1);
            continue;
        }

        if (is_starting_identifier_char(current)) {
            const char *start = current;
            while (is_identifier_char(++current)) {
            }
            std::string_view word_view(start, current);

            // at this point, content can either be a regular identifier or a keyword. let's use the
            // hash table generated by gperf to check.
            const auto *kw = KeywordHash::in_word_set(word_view.data(), word_view.size());
            if (kw) {
                tokens.emplace_back(kw->type, word_view);
                continue;
            }

            constants.emplace_back(std::string(word_view));
            tokens.emplace_back(IDENT, word_view, constants.size() - 1);
            continue;
        }

        if (*current == '"') {
            const char *start = ++current;
            std::string string;
            while (*current != '"' && *current != EOF) {
                if (*current == '\\' && *(current + 1) != EOF) [[unlikely]] {
                    switch (*(current + 1)) {
                    case 'n':
                        string += '\n';
                        current += 2;
                        continue;
                    case 'r':
                        string += '\r';
                        current += 2;
                        continue;
                    case 't':
                        string += '\t';
                        current += 2;
                        continue;
                    default: string += *(current++);
                    }
                } else [[likely]]
                    string += *(current++);
            }
            constants.emplace_back(std::move(string));
            tokens.emplace_back(STRING, std::string_view(start, current), constants.size() - 1);
            ++current;
            continue;
        }

        errors.push_back(
            Error::create(ErrorKind::LexError, SourceSpan(0, 0), "could not recognize token"));
        ++current;
    }
    tokens.emplace_back(END, std::string_view(current - 1));
}

inline void Lexer::consume_and_push(TokenType tt, size_t length) {
    tokens.emplace_back(tt, std::string_view(current, length));
    current += length;
}
} // namespace tachyon::lexer